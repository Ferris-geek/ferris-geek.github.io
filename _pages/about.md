---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a master student at [ANS Group](https://meridiancas.github.io/index.html), [Institute of Computeing Technology](http://www.ict.cas.cn), [Chinese Academy of Sciences](https://www.cas.cn)(‰∏≠ÂõΩÁßëÂ≠¶Èô¢ËÆ°ÁÆóÊäÄÊúØÁ†îÁ©∂ÊâÄ), advised by [Yu Hu](https://people.ucas.edu.cn/~huyu) and [Jilin Mei](https://scholar.google.com/citations?user=WOQhmr8AAAAJ&hl=en) .

I graduated from Zhejiang University (ÊµôÊ±üÂ§ßÂ≠¶) with a geophysics bachelor‚Äôs degree, advised by [BoYang](https://person.zju.edu.cn/boyang) and [Yixian Xu](https://person.zju.edu.cn/xyx/759477.html).

I believe math and physics are the answers to artificial intelligence. I am trying to integrate more math knowledge with my research.

My interests includes generative model, computer vision and autonomous driving.

Email: maofangyuan23s[at]ict[dot]ac[dot]cn, fangyuanmaocs[at]gmail[dot]com

# üî• News

- 2025.11, 2 papers are accepted by AAAI 2026!
- 2025.08, we release *Omni-Effects* for composite visual effects video generation!
- 2025.05, one paper is accepted by Big Data and Earth System!
- 2025.05, one paper is accepted by Pattern Recognition!
- 2023.04, one paper is accepted by IJCV!

# üìù Publications

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">AAAI 2026</div><img src='images/paper_VFX.GIF' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1"> 

[*Omni-Effects*: Unified and Spatially-Controllable Visual Effects Generation](https://arxiv.org/abs/2508.07981v1)

**Fangyuan Mao$^\dagger$**, Aiming Hao$^\dagger$, Jintao Chen, Dongxia Liu, Xiaokun Feng, Jiashu Zhu, Meiqi Wu, Chubin Chen, Jiahong Wu, Xiangxiang Chu

- Accepted by AAAI 2026.
- [[Paper]](https://arxiv.org/abs/2508.07981v1)[[Project]](https://amap-ml.github.io/Omni-Effects.github.io/)[[Code]](https://github.com/AMAP-ML/Omni-Effects)[[HuggingFace]](https://huggingface.co/GD-ML/Omni-Effects)[[Dataset]](https://huggingface.co/datasets/GD-ML/Omni-VFX)

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">Pattern Recognition</div><img src='images/paper_pid.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[**PID**: Physics-Informed Diffusion Model for Infrared Image Generation](https://doi.org/10.1016/j.patcog.2025.111816)

**Fangyuan Mao**, Jilin Mei, Shun Lu, Fuyang Liu, Liang Chen, Fangzhou Zhao, Yu Hu*

- Accepted by Pattern Recognition (JCR Q1).
- [[Paper]](https://doi.org/10.1016/j.patcog.2025.111816)[[Code]](https://github.com/fangyuanmao/PID)

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">Arxiv</div><img src='images/paper_univ.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> 

[**UNIV**: Unified Foundation Model for Infrared and Visible Modalities](https://arxiv.org/abs/2509.15642)

**Fangyuan Mao$^\dagger$**, Shuo Wang$^\dagger$, Jilin Mei, Shun Lu, Chen Min, Fuyang Liu, Xiaokun Feng, Meiqi Wu, Yu Hu

- Under Review
- [[Paper]](https://arxiv.org/abs/2509.15642)[[Code]](https://github.com/fangyuanmao/UNIV)

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">BDES 2025</div><img src='images/paper_BDES.png' alt="sym" width="85%"></div></div>
<div class='paper-box-text' markdown="1">

[Recovering Missing Regions of Earth Magnetic Anomaly Grid data (EMAG2) Using RePaint based on Diffusion Model](https://doi.org/10.1016/j.bdes.2025.100004)

**Fangyuan Mao**, Bo Yang*, Shenyao Jin

- Accepted by Big Data and Earth System 2025.
- [[Paper]](https://doi.org/10.1016/j.bdes.2025.100004)[[Code]](https://github.com/fangyuanmao/EMAG2-Completion)

</div>

</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCV 2023</div><img src='images/paper_dcsn.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Disassembling Convolutional Segmentation Network](https://link.springer.com/article/10.1007/s11263-023-01776-z)

Kaiwen Hu, Jing Gao, **Fangyuan Mao**, Xinhui Song, Lechao Cheng, Zunlei Feng, Mingli Song*

- Accepted by International Journal of Computer Vision 2023.
- [[Paper]](https://link.springer.com/article/10.1007/s11263-023-01776-z)

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">IROS 2025</div><img src='images/paper_corenet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**CORENet**: Cross-Modal 4D Radar Denoising Network with LiDAR Supervision for Autonomous Driving](https://www.arxiv.org/abs/2508.13485)

Fuyang Liu, Jilin Mei*, **Fangyuan Mao**, Yu Hu, Chen Min, Yan Xing

- Accepted by Intelligent Robots and Systems 2025
- [[Paper]](https://www.arxiv.org/abs/2508.13485)[[Code]](https://github.com/charlesuv/corenet)

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">AAAI 2026</div><img src='images/paper_imagrysearch.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**ImagerySearch**: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints](https://arxiv.org/abs/2510.14847v1)

Meiqi Wu, Jiashu Zhu, Xiaokun Feng, Chubin Chen, Chen Zhu, Bingze Song, **Fangyuan Mao**, Jiahong Wu, Xiangxiang Chu, Kaiqi Huang

- Accepted by AAAI 2026.
- [[Paper]](https://arxiv.org/abs/2510.14847v1)[[Code]](https://github.com/AMAP-ML/ImagerySearch)

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">Under Review</div><img src='images/paper_SEA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

SEA: Hierarchically Searching Efficient Adapters for Pre-trained Models

Shun Lu, **Fangyuan Mao**, Longxing Yang, Zihao Sun, Jilin Mei, Jianchao Tan, Chengru Song, Yu Hu 

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">Under Review</div><img src='images/paper_MIGA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

MIGA: Make Train-Free Infinite Frame Generation Great Again for Consistent Long Videos

Xiaokun Feng, Jiashu Zhu, Meiqi Wu, Chubin Chen, **Fangyuan Mao**, Haiyang Guo, Jiahong Wu, Xiangxiang Chu, Kaiqi Huang 

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">Arxiv 2025</div><img src='images/paper_s2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[$S^2$-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)

Chubin Chen, Jiashu Zhu, Xiaokun Feng, Nisha Huang, Meiqi Wu, **Fangyuan Mao**, Jiahong Wu, Xiangxiang Chu, Xiu Li

- [[Paper]](https://arxiv.org/abs/2508.12880)[[Project]](https://s2guidance.github.io/)[[Code]](https://github.com/AMAP-ML/S2-Guidance)

</div>

</div>

<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge">Arxiv 2025</div><img src='images/paper_ORAD.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks](https://arxiv.org/pdf/2510.16500)

Chen Min, Jilin Mei, Heng Zhai, Shuai Wang, Tong Sun, Fanjie Kong, Haoyang Li, **Fangyuan Mao**, Fuyang Liu, Shuo Wang, Yiming Nie, Qi Zhu, Liang Xiao, Dawei Zhao, Yu Hu

- [[Paper]](https://arxiv.org/pdf/2510.16500)[[Code]](https://github.com/chaytonmin/ORAD-3D)

</div>

</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2024</div><img src='images/paper_ADUE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Autonomous Driving in Unstructured Environments: How Far Have We Come?](https://arxiv.org/abs/2410.07701)

Chen Min, Shubin Si, Xu Wang, Hanzhang Xue, Weizhong Jiang, Yang Liu, Juan Wang, Qingtian Zhu, Qi Zhu, Lun Luo, Fanjie Kong, Jinyu Miao, Xudong Cai, Shuai An, Wei Li, Jilin Mei, Tong Sun, Heng Zhai, Qifeng Liu, Fangzhou Zhao, Liang Chen, Shuai Wang, Erke Shang, Linzhi Shang, Kunlong Zhao, Fuyang Li, Hao Fu, Lei Jin, Jian Zhao, **Fangyuan Mao**, Zhipeng Xiao, Chengyang Li, Bin Dai, Dawei Zhao, Liang Xiao, Yiming Nie, Yu Hu, Xuelong Li

</div>

</div>

# üéñ Honors and Awards

- *2025.01* Yifangda Financial Technology Master's Award (Top 2%).
- *2023.06* Outstanding graduate of Zhejiang University.
- *2020.09 and 2021.09* Zhejiang Provincial Government Scholarship (Top 3%).

# üìñ Educations

- *2023.09 - now*, Institute of Computing Technology, Chinese Academy of Sciences.
- *2019.09 - 2023.06*, Zhejiang University.
